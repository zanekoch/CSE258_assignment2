{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding_sequence(seq, max_len = 501, repkey = 'N'):\n",
    "    seq_len = len(seq)\n",
    "    if seq_len < max_len:\n",
    "        gap_len = max_len -seq_len\n",
    "        new_seq = seq + repkey * gap_len\n",
    "    else:\n",
    "        new_seq = seq[:max_len]\n",
    "    return new_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_RNA_seq_concolutional_array(seq, motif_len = 4):\n",
    "    seq = seq.replace('U', 'T')\n",
    "    alpha = 'ACGT'\n",
    "    #for seq in seqs:\n",
    "    #for key, seq in seqs.iteritems():\n",
    "    row = (len(seq) + 2*motif_len - 2)\n",
    "    new_array = np.zeros((row, 4))\n",
    "    for i in range(motif_len-1):\n",
    "        new_array[i] = np.array([0.25]*4)\n",
    "    \n",
    "    for i in range(row-3, row):\n",
    "        new_array[i] = np.array([0.25]*4)\n",
    "        \n",
    "    #pdb.set_trace()\n",
    "    for i, val in enumerate(seq):\n",
    "        i = i + motif_len-1\n",
    "        if val not in 'ACGT':\n",
    "            new_array[i] = np.array([0.25]*4)\n",
    "            continue\n",
    "        #if val == 'N' or i < motif_len or i > len(seq) - motif_len:\n",
    "        #    new_array[i] = np.array([0.25]*4)\n",
    "        #else:\n",
    "        try:\n",
    "            index = alpha.index(val)\n",
    "            new_array[i][index] = 1\n",
    "        except:\n",
    "            pdb.set_trace()\n",
    "        #data[key] = new_array\n",
    "    return new_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bag_data_1_channel(data, max_len = 501):\n",
    "    bags = []\n",
    "    seqs = data[\"seq\"]\n",
    "    labels = data[\"Y\"]\n",
    "    for seq in seqs:\n",
    "        #pdb.set_trace()\n",
    "        #bag_seqs = split_overlap_seq(seq)\n",
    "        \n",
    "        # replace each sequence with the sequence followed by N's until the length is equal to max_len\n",
    "        bag_seq = padding_sequence(seq, max_len = max_len)\n",
    "        #flat_array = []\n",
    "        bag_subt = []\n",
    "        #for bag_seq in bag_seqs:\n",
    "        \n",
    "        # turn the padded sequence into a 2-D array, where a row of the array is [.25,.25,.25,.25] for an N, and [1,0,0,0] for an A, [0,1,0,0] for an T, and so on\n",
    "        tri_fea = get_RNA_seq_concolutional_array(bag_seq)\n",
    "        bag_subt.append(tri_fea.T)\n",
    "\n",
    "        \n",
    "        bags.append(np.array(bag_subt))\n",
    "    \n",
    "        \n",
    "    return bags, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_seq_graphprot(seq_file, label = 1):\n",
    "    seq_list = []\n",
    "    labels = []\n",
    "    seq = ''\n",
    "    with open(seq_file, 'r') as fp:\n",
    "        for line in fp:\n",
    "            if line[0] == '>':\n",
    "                name = line[1:-1]\n",
    "            else:\n",
    "                seq = line[:-1].upper()\n",
    "                seq = seq.replace('T', 'U')\n",
    "                seq_list.append(seq)\n",
    "                labels.append(label)\n",
    "    \n",
    "    return seq_list, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_file(posifile, negafile = None, train = True):\n",
    "    data = dict()\n",
    "    seqs, labels = read_seq_graphprot(posifile, label = 1)\n",
    "    if negafile:\n",
    "        seqs2, labels2 = read_seq_graphprot(negafile, label = 0)\n",
    "        seqs = seqs + seqs2\n",
    "        labels = labels + labels2\n",
    "    # made a dictionary, \"seq\" key has a list of sequences as values, \"Y\" key has a list of 0's and 1's as values inidicating if the corresponding sequence is bound or not\n",
    "    data[\"seq\"] = seqs \n",
    "    data[\"Y\"] = np.array(labels)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(posi, nega = None, channel = 7,  window_size = 101, train = True):\n",
    "    data = read_data_file(posi, nega, train = train)\n",
    "    if channel == 1:\n",
    "        # pad the sequences and turn them into one-hot-encoded 2D arrays\n",
    "        train_bags, label = get_bag_data_1_channel(data, max_len = window_size)\n",
    "\n",
    "    else:\n",
    "        train_bags, label = get_bag_data(data, channel = channel, window_size = window_size)\n",
    "    \n",
    "    return train_bags, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK 1: data exploration\n",
    "train_data_dict = read_data_file('./CLIPSEQ_AGO2.train.positives.fa', './CLIPSEQ_AGO2.train.negatives.fa', train=True)\n",
    "test_data_dict = read_data_file('./CLIPSEQ_AGO2.ls.positives.fa', './CLIPSEQ_AGO2.ls.negatives.fa', train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of training samples is 92346 and the number of testing samples is 1000\n",
      "The average sequence length is 335.3414333051783 basepairs\n",
      "The number of positive training samples is 48095, negative 44251, positive testing 500, negative testing 500\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of training samples is {} and the number of testing samples is {}\".format(len(train_data_dict[\"seq\"]), len(test_data_dict[\"seq\"])))\n",
    "\n",
    "sum = 0\n",
    "for seq in train_data_dict[\"seq\"]:\n",
    "    sum += len(seq)\n",
    "avg_seq_len = sum/len(train_data_dict[\"seq\"])\n",
    "\n",
    "sum = 0\n",
    "\n",
    "\n",
    "\n",
    "print(\"The average sequence length is {} basepairs\".format(avg_seq_len))\n",
    "\n",
    "pos = train_data_dict[\"Y\"].sum()\n",
    "pos_test = test_data_dict[\"Y\"].sum()\n",
    "print(\"The number of positive training samples is {}, negative {}, positive testing {}, negative testing {}\".format(pos, len(train_data_dict[\"Y\"])-pos, pos_test, len(test_data_dict[\"Y\"])-pos_test ))                                                                                                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the data \n",
    "f, l = get_data('./CLIPSEQ_AGO2.train.positives.fa', './CLIPSEQ_AGO2.train.negatives.fa', channel=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_test, l_test = get_data('./CLIPSEQ_AGO2.ls.positives.fa','CLIPSEQ_AGO2.ls.negatives.fa', channel=1, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = np.array(f)\n",
    "f = np.swapaxes(f, -1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_test = np.array(f_test)\n",
    "f_test = np.swapaxes(f_test, -1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-25 12:16:24.322117: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-11-25 12:16:24.420942: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-25 12:16:24.514542: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 107, 4, 128)       3968      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 107, 4, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 35, 4, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 35, 4, 128)        163968    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 35, 4, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 11, 4, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 11, 4, 256)        164096    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 11, 4, 256)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 365,057\n",
      "Trainable params: 365,057\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(128, kernel_size=(10, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=f.shape[1:], padding='same'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(MaxPooling2D(pool_size=(3, 1)))\n",
    "model.add(Conv2D(128, (10, 1), activation='relu', padding='same'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(MaxPooling2D(pool_size=(3, 1)))\n",
    "model.add(Conv2D(256, (5, 1), activation='relu', padding='same'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(keras.layers.GlobalAveragePooling2D())\n",
    "model.add(Dropout(0.25))\n",
    "# model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.binary_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-25 12:16:25.049049: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-11-25 12:16:25.094872: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2345700000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "361/361 [==============================] - 441s 1s/step - loss: 0.6940 - accuracy: 0.4952 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 2/50\n",
      "361/361 [==============================] - 426s 1s/step - loss: 0.6936 - accuracy: 0.4998 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 3/50\n",
      "361/361 [==============================] - 426s 1s/step - loss: 0.6935 - accuracy: 0.5013 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 4/50\n",
      "361/361 [==============================] - 426s 1s/step - loss: 0.6931 - accuracy: 0.5077 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 5/50\n",
      "361/361 [==============================] - 426s 1s/step - loss: 0.6932 - accuracy: 0.5096 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 6/50\n",
      "361/361 [==============================] - 426s 1s/step - loss: 0.6927 - accuracy: 0.5134 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 7/50\n",
      "361/361 [==============================] - 426s 1s/step - loss: 0.6926 - accuracy: 0.5170 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 8/50\n",
      "361/361 [==============================] - 426s 1s/step - loss: 0.6930 - accuracy: 0.5127 - val_loss: 0.6934 - val_accuracy: 0.5000\n",
      "Epoch 9/50\n",
      "361/361 [==============================] - 426s 1s/step - loss: 0.6928 - accuracy: 0.5140 - val_loss: 0.6934 - val_accuracy: 0.5000\n",
      "Epoch 10/50\n",
      "361/361 [==============================] - 425s 1s/step - loss: 0.6929 - accuracy: 0.5133 - val_loss: 0.6934 - val_accuracy: 0.5000\n",
      "Epoch 11/50\n",
      "361/361 [==============================] - 426s 1s/step - loss: 0.6928 - accuracy: 0.5153 - val_loss: 0.6934 - val_accuracy: 0.5000\n",
      "Epoch 12/50\n",
      "361/361 [==============================] - 426s 1s/step - loss: 0.6927 - accuracy: 0.5175 - val_loss: 0.6935 - val_accuracy: 0.5000\n",
      "Epoch 13/50\n",
      "361/361 [==============================] - 426s 1s/step - loss: 0.6927 - accuracy: 0.5161 - val_loss: 0.6935 - val_accuracy: 0.5000\n",
      "Epoch 14/50\n",
      "361/361 [==============================] - 426s 1s/step - loss: 0.6927 - accuracy: 0.5188 - val_loss: 0.6935 - val_accuracy: 0.5000\n",
      "Epoch 15/50\n",
      "361/361 [==============================] - 426s 1s/step - loss: 0.6926 - accuracy: 0.5184 - val_loss: 0.6935 - val_accuracy: 0.5000\n",
      "Epoch 16/50\n",
      "361/361 [==============================] - 428s 1s/step - loss: 0.6926 - accuracy: 0.5171 - val_loss: 0.6935 - val_accuracy: 0.5000\n",
      "Epoch 17/50\n",
      "361/361 [==============================] - 426s 1s/step - loss: 0.6922 - accuracy: 0.5224 - val_loss: 0.6935 - val_accuracy: 0.5000\n",
      "Epoch 18/50\n",
      "361/361 [==============================] - 427s 1s/step - loss: 0.6923 - accuracy: 0.5205 - val_loss: 0.6935 - val_accuracy: 0.5000\n",
      "Epoch 19/50\n",
      "361/361 [==============================] - 426s 1s/step - loss: 0.6923 - accuracy: 0.5187 - val_loss: 0.6935 - val_accuracy: 0.5000\n",
      "Epoch 20/50\n",
      "361/361 [==============================] - 426s 1s/step - loss: 0.6927 - accuracy: 0.5158 - val_loss: 0.6935 - val_accuracy: 0.5000\n",
      "Epoch 21/50\n",
      "361/361 [==============================] - 426s 1s/step - loss: 0.6926 - accuracy: 0.5186 - val_loss: 0.6935 - val_accuracy: 0.5000\n",
      "Epoch 22/50\n",
      "361/361 [==============================] - 426s 1s/step - loss: 0.6926 - accuracy: 0.5190 - val_loss: 0.6935 - val_accuracy: 0.5000\n",
      "Epoch 23/50\n",
      "361/361 [==============================] - 426s 1s/step - loss: 0.6926 - accuracy: 0.5169 - val_loss: 0.6935 - val_accuracy: 0.5000\n",
      "Epoch 24/50\n",
      "361/361 [==============================] - 426s 1s/step - loss: 0.6926 - accuracy: 0.5183 - val_loss: 0.6935 - val_accuracy: 0.5000\n",
      "Epoch 25/50\n",
      "361/361 [==============================] - 426s 1s/step - loss: 0.6926 - accuracy: 0.5190 - val_loss: 0.6935 - val_accuracy: 0.5000\n",
      "Epoch 26/50\n",
      "361/361 [==============================] - 426s 1s/step - loss: 0.6925 - accuracy: 0.5190 - val_loss: 0.6935 - val_accuracy: 0.5000\n",
      "Epoch 27/50\n",
      "361/361 [==============================] - 426s 1s/step - loss: 0.6925 - accuracy: 0.5184 - val_loss: 0.6935 - val_accuracy: 0.5000\n",
      "Epoch 28/50\n",
      "361/361 [==============================] - 426s 1s/step - loss: 0.6923 - accuracy: 0.5187 - val_loss: 0.6935 - val_accuracy: 0.5000\n",
      "Epoch 29/50\n",
      "361/361 [==============================] - 426s 1s/step - loss: 0.6925 - accuracy: 0.5194 - val_loss: 0.6934 - val_accuracy: 0.5000\n",
      "Epoch 30/50\n",
      "361/361 [==============================] - 426s 1s/step - loss: 0.6924 - accuracy: 0.5193 - val_loss: 0.6934 - val_accuracy: 0.5000\n",
      "Epoch 31/50\n",
      "361/361 [==============================] - 426s 1s/step - loss: 0.6923 - accuracy: 0.5193 - val_loss: 0.6934 - val_accuracy: 0.5000\n",
      "Epoch 32/50\n",
      "361/361 [==============================] - 426s 1s/step - loss: 0.6922 - accuracy: 0.5207 - val_loss: 0.6934 - val_accuracy: 0.5000\n",
      "Epoch 33/50\n",
      "361/361 [==============================] - 426s 1s/step - loss: 0.6921 - accuracy: 0.5228 - val_loss: 0.6934 - val_accuracy: 0.5000\n",
      "Epoch 34/50\n",
      "361/361 [==============================] - 426s 1s/step - loss: 0.6925 - accuracy: 0.5188 - val_loss: 0.6934 - val_accuracy: 0.5000\n",
      "Epoch 35/50\n",
      "361/361 [==============================] - 426s 1s/step - loss: 0.6923 - accuracy: 0.5215 - val_loss: 0.6934 - val_accuracy: 0.5000\n",
      "Epoch 36/50\n",
      "361/361 [==============================] - 426s 1s/step - loss: 0.6923 - accuracy: 0.5210 - val_loss: 0.6934 - val_accuracy: 0.5000\n",
      "Epoch 37/50\n",
      "361/361 [==============================] - 426s 1s/step - loss: 0.6924 - accuracy: 0.5194 - val_loss: 0.6934 - val_accuracy: 0.5000\n",
      "Epoch 38/50\n",
      "361/361 [==============================] - 426s 1s/step - loss: 0.6924 - accuracy: 0.5198 - val_loss: 0.6934 - val_accuracy: 0.5000\n",
      "Epoch 39/50\n",
      "361/361 [==============================] - 426s 1s/step - loss: 0.6922 - accuracy: 0.5209 - val_loss: 0.6934 - val_accuracy: 0.5000\n",
      "Epoch 40/50\n",
      "361/361 [==============================] - 426s 1s/step - loss: 0.6920 - accuracy: 0.5223 - val_loss: 0.6934 - val_accuracy: 0.5000\n",
      "Epoch 41/50\n",
      "361/361 [==============================] - 426s 1s/step - loss: 0.6922 - accuracy: 0.5208 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 42/50\n",
      "361/361 [==============================] - 426s 1s/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 43/50\n",
      "361/361 [==============================] - 426s 1s/step - loss: 0.6923 - accuracy: 0.5196 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 44/50\n",
      "361/361 [==============================] - 426s 1s/step - loss: 0.6924 - accuracy: 0.5193 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 45/50\n",
      "361/361 [==============================] - 426s 1s/step - loss: 0.6920 - accuracy: 0.5234 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 46/50\n",
      "361/361 [==============================] - 426s 1s/step - loss: 0.6921 - accuracy: 0.5212 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 47/50\n",
      "361/361 [==============================] - 426s 1s/step - loss: 0.6923 - accuracy: 0.5192 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 48/50\n",
      "361/361 [==============================] - 426s 1s/step - loss: 0.6923 - accuracy: 0.5197 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 49/50\n",
      "361/361 [==============================] - 426s 1s/step - loss: 0.6924 - accuracy: 0.5176 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 50/50\n",
      "361/361 [==============================] - 426s 1s/step - loss: 0.6923 - accuracy: 0.5207 - val_loss: 0.6932 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1554ec734070>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(f, l,\n",
    "          batch_size=256,\n",
    "          epochs=50,\n",
    "          verbose=1,\n",
    "          validation_data=(f_test, l_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
