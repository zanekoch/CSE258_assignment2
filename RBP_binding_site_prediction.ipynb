{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Data reading methods</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding_sequence(seq, max_len = 501, repkey = 'N'):\n",
    "    seq_len = len(seq)\n",
    "    if seq_len < max_len:\n",
    "        gap_len = max_len -seq_len\n",
    "        new_seq = seq + repkey * gap_len\n",
    "    else:\n",
    "        new_seq = seq[:max_len]\n",
    "    return new_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_RNA_seq_concolutional_array(seq, motif_len = 4):\n",
    "    seq = seq.replace('U', 'T')\n",
    "    alpha = 'ACGT'\n",
    "    #for seq in seqs:\n",
    "    #for key, seq in seqs.iteritems():\n",
    "    row = (len(seq) + 2*motif_len - 2)\n",
    "    new_array = np.zeros((row, 4))\n",
    "    for i in range(motif_len-1):\n",
    "        new_array[i] = np.array([0.25]*4)\n",
    "    \n",
    "    for i in range(row-3, row):\n",
    "        new_array[i] = np.array([0.25]*4)\n",
    "        \n",
    "    #pdb.set_trace()\n",
    "    for i, val in enumerate(seq):\n",
    "        i = i + motif_len-1\n",
    "        # add .25's because this val is an N\n",
    "        if val not in 'ACGT':\n",
    "            new_array[i] = np.array([0.25]*4)\n",
    "            continue\n",
    "        #if val == 'N' or i < motif_len or i > len(seq) - motif_len:\n",
    "        #    new_array[i] = np.array([0.25]*4)\n",
    "        #else:\n",
    "        try:\n",
    "            index = alpha.index(val)\n",
    "            new_array[i][index] = 1\n",
    "        except:\n",
    "            pdb.set_trace()\n",
    "        #data[key] = new_array\n",
    "    return new_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bag_data_1_channel(data, max_len = 501):\n",
    "    bags = []\n",
    "    seqs = data[\"seq\"]\n",
    "    labels = data[\"Y\"]\n",
    "    for seq in seqs:\n",
    "        #pdb.set_trace()\n",
    "        #bag_seqs = split_overlap_seq(seq)\n",
    "        \n",
    "        # replace each sequence with the sequence followed by N's until the length is equal to max_len\n",
    "        bag_seq = padding_sequence(seq, max_len = max_len)\n",
    "        #flat_array = []\n",
    "        bag_subt = []\n",
    "        #for bag_seq in bag_seqs:\n",
    "        \n",
    "        # turn the padded sequence into a 2-D array, where a row of the array is [.25,.25,.25,.25] for an N, and [1,0,0,0] for an A, [0,1,0,0] for an T, and so on\n",
    "        tri_fea = get_RNA_seq_concolutional_array(bag_seq)\n",
    "        bag_subt.append(tri_fea.T)\n",
    "\n",
    "        \n",
    "        bags.append(np.array(bag_subt))\n",
    "    \n",
    "        \n",
    "    return bags, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_seq_graphprot(seq_file, label = 1):\n",
    "    seq_list = []\n",
    "    labels = []\n",
    "    seq = ''\n",
    "    with open(seq_file, 'r') as fp:\n",
    "        for line in fp:\n",
    "            if line[0] == '>':\n",
    "                name = line[1:-1]\n",
    "            else:\n",
    "                seq = line[:-1].upper()\n",
    "                seq = seq.replace('T', 'U')\n",
    "                seq_list.append(seq)\n",
    "                labels.append(label)\n",
    "    \n",
    "    return seq_list, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_file(posifile, negafile = None, train = True):\n",
    "    data = dict()\n",
    "    seqs, labels = read_seq_graphprot(posifile, label = 1)\n",
    "    if negafile:\n",
    "        seqs2, labels2 = read_seq_graphprot(negafile, label = 0)\n",
    "        seqs = seqs + seqs2\n",
    "        labels = labels + labels2\n",
    "    # made a dictionary, \"seq\" key has a list of sequences as values, \"Y\" key has a list of 0's and 1's as values inidicating if the corresponding sequence is bound or not\n",
    "    data[\"seq\"] = seqs \n",
    "    data[\"Y\"] = np.array(labels)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(posi, nega = None, channel = 1,  window_size = 501, train = True):\n",
    "    data = read_data_file(posi, nega, train = train)\n",
    "    if channel == 1:\n",
    "        # pad the sequences and turn them into one-hot-encoded 2D arrays\n",
    "        train_bags, label = get_bag_data_1_channel(data, max_len = window_size)\n",
    "\n",
    "    else:\n",
    "        train_bags, label = get_bag_data(data, channel = channel, window_size = window_size)\n",
    "    \n",
    "    return train_bags, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Data exploration</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK 1: data exploration\n",
    "train_data_dict = read_data_file('./CLIPSEQ_AGO2.train.positives.fa', './CLIPSEQ_AGO2.train.negatives.fa', train=True)\n",
    "test_data_dict = read_data_file('./CLIPSEQ_AGO2.ls.positives.fa', './CLIPSEQ_AGO2.ls.negatives.fa', train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of training samples is 92346 and the number of testing samples is 1000\n",
      "The average sequence length is 335.3414333051783 basepairs with max length 375 and min length 137\n",
      "The number of positive training samples is 48095, negative 44251, positive testing 500, negative testing 500\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of training samples is {} and the number of testing samples is {}\".format(len(train_data_dict[\"seq\"]), len(test_data_dict[\"seq\"])))\n",
    "\n",
    "sum = 0\n",
    "max = 0\n",
    "min = 1000\n",
    "for seq in train_data_dict[\"seq\"]:\n",
    "    sum += len(seq)\n",
    "    if len(seq) > max: max = len(seq)\n",
    "    if len(seq) < min: min = len(seq)\n",
    "avg_seq_len = sum/len(train_data_dict[\"seq\"])\n",
    "\n",
    "print(\"The average sequence length is {} basepairs with max length {} and min length {}\".format(avg_seq_len, max, min))\n",
    "\n",
    "pos = train_data_dict[\"Y\"].sum()\n",
    "pos_test = test_data_dict[\"Y\"].sum()\n",
    "print(\"The number of positive training samples is {}, negative {}, positive testing {}, negative testing {}\".format(pos, len(train_data_dict[\"Y\"])-pos, pos_test, len(test_data_dict[\"Y\"])-pos_test ))                                                                                                         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Read in data and format for NN</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the data \n",
    "f, l = get_data('./CLIPSEQ_AGO2.train.positives.fa', './CLIPSEQ_AGO2.train.negatives.fa', channel=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_test, l_test = get_data('./CLIPSEQ_AGO2.ls.positives.fa','CLIPSEQ_AGO2.ls.negatives.fa', channel=1, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = np.array(f)\n",
    "f = np.swapaxes(f, -1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_test = np.array(f_test)\n",
    "f_test = np.swapaxes(f_test, -1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Model training</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import applications\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten,BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Provided model from the github</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(128, kernel_size=(10, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=f.shape[1:], padding='same'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(MaxPooling2D(pool_size=(3, 1)))\n",
    "model.add(Conv2D(128, (10, 1), activation='relu', padding='same'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(MaxPooling2D(pool_size=(3, 1)))\n",
    "model.add(Conv2D(256, (5, 1), activation='relu', padding='same'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(keras.layers.GlobalAveragePooling2D())\n",
    "model.add(Dropout(0.25))\n",
    "# model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = SGD(lr=0.01)\n",
    "# model.compile(loss=keras.losses.binary_crossentropy, optimizer=keras.optimizers.Adadelta(),metrics=['accuracy'])\n",
    "model.compile(loss=keras.losses.binary_crossentropy, optimizer=opt,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(f, l,\n",
    "          batch_size=10,\n",
    "          epochs=5,\n",
    "          verbose=1,\n",
    "          validation_data=(f_test, l_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(507, 4, 1)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.shape[1:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Simple CNN Model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_16 (Conv2D)           (None, 507, 4, 128)       5248      \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 507, 4, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 126, 4, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 126, 4, 128)       163968    \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 126, 4, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 126, 4, 128)       512       \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_6 ( (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 186,369\n",
      "Trainable params: 186,113\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "simple_model = Sequential()\n",
    "# learning 128 different convolution filters => results 128 tensors output after this layer\n",
    "# s\n",
    "simple_model.add(Conv2D(128, kernel_size=(10, 4),\n",
    "                 activation='relu',\n",
    "                 input_shape=f.shape[1:], padding='same'))\n",
    "simple_model.add(Dropout(0.25))\n",
    "simple_model.add(MaxPooling2D(pool_size=(4, 1)))\n",
    "simple_model.add(Conv2D(128, (10, 1), activation='relu', padding='same'))\n",
    "simple_model.add(Dropout(0.25))\n",
    "simple_model.add(BatchNormalization())\n",
    "simple_model.add(keras.layers.GlobalAveragePooling2D())\n",
    "simple_model.add(Dense(128, activation='relu'))\n",
    "simple_model.add(Dropout(0.5))\n",
    "simple_model.add(Dense(1, activation='sigmoid'))\n",
    "simple_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = SGD(lr=0.01)\n",
    "# model.compile(loss=keras.losses.binary_crossentropy, optimizer=keras.optimizers.Adadelta(),metrics=['accuracy'])\n",
    "simple_model.compile(loss=keras.losses.binary_crossentropy, optimizer=opt,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(92346, 507, 4, 1)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000,)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# subset the training data\n",
    "to_del = [i for i in range(20000,92346-20000)]\n",
    "f_sub = np.delete(f, to_del, 0)\n",
    "l_sub = np.delete(l, to_del, 0)\n",
    "l_sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_model.fit(f, l,\n",
    "          batch_size=10,\n",
    "          epochs=50,\n",
    "          verbose=1,\n",
    "          validation_data=(f_test, l_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> ResNet Model </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Baselines</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hamming and edit distance baseline\n",
    "from tinyalign import edit_distance, hamming_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent done: 0.1%\n",
      "Percent done: 0.2%\n",
      "Percent done: 0.3%\n",
      "Percent done: 0.4%\n",
      "Percent done: 0.5%\n",
      "Percent done: 0.6%\n",
      "Percent done: 0.7%\n",
      "Percent done: 0.8%\n",
      "Percent done: 0.9%\n",
      "Percent done: 1.0%\n",
      "edit distance baseline validation accuracy 0.5\n"
     ]
    }
   ],
   "source": [
    "# edit distance baseline\n",
    "# done on raw, unpadded reads => length differences count toward edit distance\n",
    "correct_predictions = 0\n",
    "n = 1\n",
    "for seq, label in zip (test_data_dict[\"seq\"], test_data_dict[\"Y\"]):\n",
    "    min_dist = 1000\n",
    "    # calculate edit distance between test seq and each of the training sequences (only use 10,000 for computation time)\n",
    "    for train_seq, train_label in zip( train_data_dict[\"seq\"][:10000],  train_data_dict[\"Y\"][:10000] ):\n",
    "        dist = edit_distance(seq, train_seq)\n",
    "        if dist < min_dist: \n",
    "            min_dist = dist\n",
    "            min_dist_label = train_label\n",
    "    # will add one for each correct prediciton\n",
    "    if min_dist_label == label:\n",
    "        correct_predictions += 1\n",
    "    if n%100 == 0:\n",
    "        print(\"Percent done: {}%\".format(n/1000))\n",
    "    n+=1\n",
    "\n",
    "print(\"edit distance baseline validation accuracy {}\".format(correct_predictions/len(test_data_dict[\"Y\"])))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad all the sequences\n",
    "padded_test_data_dict = {}\n",
    "padded_test_data_dict[\"Y\"] = test_data_dict[\"Y\"]\n",
    "padded_train_data_dict = {}\n",
    "padded_train_data_dict[\"Y\"] = train_data_dict[\"Y\"]\n",
    "\n",
    "padded_test = []\n",
    "for seq in test_data_dict[\"seq\"]:\n",
    "    padded_test.append(padding_sequence(seq))\n",
    "padded_test_data_dict[\"seq\"] = padded_test\n",
    "\n",
    "padded_train = []\n",
    "for seq in train_data_dict[\"seq\"]:\n",
    "    padded_train.append(padding_sequence(seq))\n",
    "padded_train_data_dict[\"seq\"] = padded_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent done: 0.1%\n",
      "Percent done: 0.2%\n",
      "Percent done: 0.3%\n",
      "Percent done: 0.4%\n",
      "Percent done: 0.5%\n",
      "Percent done: 0.6%\n",
      "Percent done: 0.7%\n",
      "Percent done: 0.8%\n",
      "Percent done: 0.9%\n",
      "Percent done: 1.0%\n",
      "hamming distance baseline validation accuracy 0.635\n"
     ]
    }
   ],
   "source": [
    "# hamming distance baseline\n",
    "# this is done on the reads once they have already been padded with N's, so they are all the same length\n",
    "correct_predictions = 0\n",
    "n = 1\n",
    "for seq, label in zip (padded_test_data_dict[\"seq\"], padded_test_data_dict[\"Y\"]):\n",
    "    min_dist = 1000\n",
    "    # calculate edit distance between test seq and each of the training sequences \n",
    "    for train_seq, train_label in zip(padded_train_data_dict[\"seq\"], padded_train_data_dict[\"Y\"]):\n",
    "        dist = hamming_distance(seq, train_seq)\n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "            min_dist_label = train_label\n",
    "    # will add one for each correct prediciton\n",
    "    if min_dist_label == label:\n",
    "        correct_predictions += 1\n",
    "    if n%100 == 0:\n",
    "        print(\"Percent done: {}%\".format(n/1000))\n",
    "    n+=1\n",
    "\n",
    "print(\"hamming distance baseline validation accuracy {}\".format(correct_predictions/len(test_data_dict[\"Y\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a>edit distance baseline validation accuracy 0.5</a>\n",
    "<a>hamming distance baseline validation accuracy 0.635</a>"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "703f02bdb79bc8f251e1db33fb6f1fa012df65abb324d1bf7de099e1be8da837"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
